{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQmWQl9Dm0T6uqx1+oTEEy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyart93/inverted_index_algo/blob/main/inverted_index_algos_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inverted Index\n",
        "\n",
        "- it is reverse index i.e. key becames value and value becames key\n",
        "- we remove common words, normalize it, remove puncuations\n",
        "- then we build the index\n",
        "- search function searchs the index by taking the query"
      ],
      "metadata": {
        "id": "qBjPw48D8yU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azk4X6U18pjQ",
        "outputId": "430ebb3b-7e96-4ac2-e33d-535832fe082b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'appearing': ['doc1'],\n",
            " 'computer': ['doc1', 'doc2'],\n",
            " 'examination': ['doc1', 'doc2'],\n",
            " 'practical': ['doc1', 'doc2'],\n",
            " 'science': ['doc1'],\n",
            " 'sciencex': ['doc2'],\n",
            " 'students': ['doc1'],\n",
            " 'today': ['doc2']}\n",
            "{'doc2'}\n",
            "set()\n",
            "{'doc1'}\n",
            "not found\n",
            "not found\n"
          ]
        }
      ],
      "source": [
        "dt = {\n",
        "    \"doc1\": \"The computer science students are appearing for practical examination.\",\n",
        "    \"doc2\": \"The computer sciencex practical examination is today?\"\n",
        "}\n",
        "\n",
        "i = {}\n",
        "sw = ['the', 'are', 'for', 'is']\n",
        "\n",
        "for k,v in dt.items():\n",
        "    v = v.lower()\n",
        "    v = v.strip('.?')\n",
        "    words = v.split()\n",
        "\n",
        "    for w in words:\n",
        "        if w in sw:\n",
        "            continue\n",
        "        if w not in i:\n",
        "            i[w] = []\n",
        "        if k not in i[w]:\n",
        "            i[w].append(k)\n",
        "\n",
        "import pprint\n",
        "pprint.pprint(i)\n",
        "\n",
        "\n",
        "def search(q):\n",
        "    q = q.strip('.?!')\n",
        "    q = q.lower().split()\n",
        "    k = []\n",
        "    for w in q:\n",
        "      if w not in i:\n",
        "          return \"not found\"\n",
        "      else:\n",
        "        k.append(i[w])\n",
        "        # print(j)\n",
        "    # print(l)\n",
        "      if len(k) == 0:\n",
        "        return \"no\"\n",
        "\n",
        "    return set(k[0]).intersection(*k[1:])\n",
        "    # without *:\n",
        "    # if len(l) == 2:\n",
        "    #   return set(l[0]).intersection(l[1])\n",
        "    # elif len(l) == 3:\n",
        "    #   return set(l[0]).intersection(l[1], l[2])\n",
        "# ... and so on for all possible lengths\n",
        "    # alt:\n",
        "    # result = set(l[0])\n",
        "    # for docs in l[1:]:\n",
        "    #     result &= set(docs)  # &= is intersection_update\n",
        "\n",
        "r = search(\"Computer Sciencex\")\n",
        "print(r)\n",
        "\n",
        "r2 = search(\"students today\")\n",
        "print(r2)\n",
        "\n",
        "r3 = search(\"students\")\n",
        "print(r3)\n",
        "\n",
        "r4 = search(\"business\")\n",
        "print(r4)\n",
        "\n",
        "r5 = search(\"ok\")\n",
        "print(r5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  print(\"Enter quit to exit\")\n",
        "  rs = input(\"Enter the query: \")\n",
        "  if rs == \"quit\":\n",
        "    break\n",
        "  # print(rs)\n",
        "  r = search(rs)\n",
        "  print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXWhXVxX9Q7V",
        "outputId": "29f87fbd-8479-420b-a8e2-1b0d22768700"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter quit to exit\n",
            "Enter the query: Computet\n",
            "not found\n",
            "Enter quit to exit\n",
            "Enter the query: Compiuter\n",
            "not found\n",
            "Enter quit to exit\n",
            "Enter the query: Computer\n",
            "{'doc2', 'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: computer.\n",
            "{'doc2', 'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: computer science\n",
            "{'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: examination\n",
            "{'doc2', 'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: practical examination\n",
            "{'doc2', 'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: tomorrow\n",
            "not found\n",
            "Enter quit to exit\n",
            "Enter the query: today\n",
            "{'doc2'}\n",
            "Enter quit to exit\n",
            "Enter the query: students\n",
            "{'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: appearing\n",
            "{'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: students appearing\n",
            "{'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "sw = stopwords.words('english')\n",
        "# print(sw)\n",
        "\n",
        "i = {}\n",
        "\n",
        "for k, v in dt.items():\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtJzNUWi9Z39",
        "outputId": "a4bb9fac-d0ba-45dd-cc10-a935362c737f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set([1,2,4]).intersection([1,2,3,4])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-Lur-qIGpWr",
        "outputId": "605bfc85-9591-461d-ffc3-6a5f2dba1fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1, 2, 4}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from string import punctuation\n",
        "import nltk\n",
        "if not nltk.corpus.stopwords.words('english'):\n",
        "  nltk.download('stopwords')\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "doc = {\n",
        "    'doc1': 'The computer science students are appearing for practical examination.',\n",
        "    'doc2': 'computer science practical examination will start tomorrow.',\n",
        "\n",
        "}\n",
        "\n",
        "i = {}\n",
        "\n",
        "for k, v in doc.items():\n",
        "  v = v.lower().strip('.?!')\n",
        "  for word in v.split():\n",
        "    if word in stop_words:\n",
        "      continue\n",
        "    if word not in i:\n",
        "      i[word] = []\n",
        "    if k not in i[word]:\n",
        "      i[word].append(k)\n",
        "\n",
        "pprint(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqndXyDlOAZ-",
        "outputId": "241dd3f9-26c0-4f75-f032-ce759f23e552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'appearing': ['doc1'],\n",
            " 'computer': ['doc1', 'doc2'],\n",
            " 'examination': ['doc1', 'doc2'],\n",
            " 'practical': ['doc1', 'doc2'],\n",
            " 'science': ['doc1', 'doc2'],\n",
            " 'start': ['doc2'],\n",
            " 'students': ['doc1'],\n",
            " 'tomorrow': ['doc2']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = {\n",
        "    \"doc1\": \"The computer science students are appearing for practical examination.\",\n",
        "    \"doc2\": \"The computer sciencex practical examination is today?\"\n",
        "}\n",
        "\n",
        "i = {}\n",
        "sw = ['the', 'are', 'for', 'is']\n",
        "\n",
        "for k,v in dt.items():\n",
        "    v = v.lower()\n",
        "    v = v.strip('.?')\n",
        "    words = v.split()\n",
        "\n",
        "    for w in words:\n",
        "        if w in sw:\n",
        "            continue\n",
        "        if w not in i:\n",
        "            i[w] = []\n",
        "        if k not in i[w]:\n",
        "            i[w].append(k)\n",
        "\n",
        "import pprint\n",
        "pprint.pprint(i)\n",
        "\n",
        "\n",
        "def search(q):\n",
        "    q = q.lower().split()\n",
        "    l = []\n",
        "    for j in q:\n",
        "        l.append(i[j])\n",
        "        # print(j)\n",
        "    print(l)\n",
        "    return list(set(l[0]).intersection(*l[1:]))\n",
        "\n",
        "r = search(\"Computer Sciencex\")\n",
        "print(r)\n",
        "\n",
        "# r2 = search(\"students today\")\n",
        "# print(r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6kNUCNqFl9O",
        "outputId": "60d132f0-fe71-4e30-f60f-a5227f428a90"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'appearing': ['doc1'],\n",
            " 'computer': ['doc1', 'doc2'],\n",
            " 'examination': ['doc1', 'doc2'],\n",
            " 'practical': ['doc1', 'doc2'],\n",
            " 'science': ['doc1'],\n",
            " 'sciencex': ['doc2'],\n",
            " 'students': ['doc1'],\n",
            " 'today': ['doc2']}\n",
            "[['doc1', 'doc2'], ['doc2']]\n",
            "['doc2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a question-answering system using techniques such as information extraction"
      ],
      "metadata": {
        "id": "Cu3b55LZgvg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "context = \"\"\"\n",
        "The computer science students are appearing for practical examination.\n",
        "Computer science practical examination will start tomorrow.\n",
        "\"\"\"\n",
        "\n",
        "def ask(question):\n",
        "    result = qa_pipeline(question=question, context=context)\n",
        "    return result['answer']\n",
        "\n",
        "print(ask(\"Who is appearing for examination?\"))  # Output: computer science students\n",
        "print(ask(\"When will the exam start?\"))         # Output: tomorrow\n",
        "print(ask(\"What is the subject?\"))\n",
        "print(ask(\"Who has exams?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmD0pf_if4-9",
        "outputId": "1b6ab83f-67f2-42bc-f3f7-b5593cc7b980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computer science students\n",
            "tomorrow\n",
            "computer science\n",
            "computer science students\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ask(\"What department of students are appearing for exam\"))\n",
        "print(ask(\"Which exam will start tomorrow\"))\n",
        "print(ask(\"Who is appearing for examination?\"))\n",
        "print(ask(\"When will the exam start?\"))\n",
        "print(ask(\"Who has exams?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlLTytiBhBdE",
        "outputId": "75aef279-fbb7-46a7-bbd1-2c10dfbb2283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computer science\n",
            "Computer science practical examination\n",
            "computer science students\n",
            "tomorrow\n",
            "computer science students\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ask(\"who am i\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7aLHy75iHZF",
        "outputId": "43065e37-471f-4661-802a-6363908966b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The computer science students\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ask(\"what is my name?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9vTIxA9iOXk",
        "outputId": "15fb7fd2-89b3-41b3-8221-aa64ef539b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The computer science students are appearing for practical examination\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context += 'my name is art'\n",
        "print(ask('what is my name?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVe_-43wiy0B",
        "outputId": "d8e6df43-31ee-402e-b6ca-9307ec7f7588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "art\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ask(\"Who has exams?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk0d-YvjiTDc",
        "outputId": "ac0b42fb-5472-4da7-cec8-5ca84847a9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computer science students\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r6eS_a8mitc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context += \"\"\"\n",
        "India has the second-largest population in the world.\n",
        "It is surrounded by oceans from three sides which are Bay Of Bengal in\n",
        "the east, the Arabian Sea in the west and Indian oceans in the south.\n",
        "Tiger is the national animal of India.\n",
        "Peacock is the national bird of India.\n",
        "\"Mango is the national fruit of India.\"\"\"\n",
        "print(ask(\"What is the national animal of India?\"))\n",
        "print(ask(\"What is the national bird of India?\"))\n",
        "print(ask(\"What is the national fruit of India?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn9LzBrUphFy",
        "outputId": "41d0bec1-6c3d-47db-8122-1edc68b25130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiger\n",
            "Peacock\n",
            "Mango\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PRxHCn17pwdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "sw = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "doc = {\n",
        "    'doc1': 'The computer science students are appearing for practical examination.',\n",
        "    'doc2': 'computer science practical examination will start tomorrow.',\n",
        "\n",
        "}\n",
        "\n",
        "i = {}\n",
        "\n",
        "for k, v in doc.items():\n",
        "  v = v.lower()\n",
        "  v = v.strip(punctuation)\n",
        "  for word in v.split():\n",
        "    if word in sw:\n",
        "      continue\n",
        "    if word not in i:\n",
        "      i[word] = []\n",
        "    if k not in i[word]:\n",
        "      i[word].append(k)\n",
        "from pprint import pprint\n",
        "pprint(doc)\n",
        "print()\n",
        "i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXZFlIg0ubHy",
        "outputId": "8a0ab2b3-5a31-45bc-9188-8caad5cca47c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'doc1': 'The computer science students are appearing for practical '\n",
            "         'examination.',\n",
            " 'doc2': 'computer science practical examination will start tomorrow.'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'computer': ['doc1', 'doc2'],\n",
              " 'science': ['doc1', 'doc2'],\n",
              " 'students': ['doc1'],\n",
              " 'appearing': ['doc1'],\n",
              " 'practical': ['doc1', 'doc2'],\n",
              " 'examination': ['doc1', 'doc2'],\n",
              " 'start': ['doc2'],\n",
              " 'tomorrow': ['doc2']}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "def search(query):\n",
        "  query = query.lower()\n",
        "  query = query.strip(punctuation)\n",
        "  query = query.split() # ['a', 'b']\n",
        "  print(query)\n",
        "  k = []\n",
        "  for w in query:\n",
        "    if w not in i:\n",
        "      return \"not found\"\n",
        "    else:\n",
        "      k.append(i[w])\n",
        "  print(k)\n",
        "  if len(k) == 0:\n",
        "    return \"no\"\n",
        "  return set(k[0]).intersection(*k[1:])\n",
        ""
      ],
      "metadata": {
        "id": "a-hUskYUukij"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(search(\"computer science students\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVTejHPYzzhZ",
        "outputId": "1b81bc42-4d7c-46d6-eba5-683f3b353225"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['computer', 'science', 'students']\n",
            "[['doc1', 'doc2'], ['doc1', 'doc2'], ['doc1']]\n",
            "{'doc1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = input()\n",
        "print(search(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVkmPZ6az19c",
        "outputId": "a7bb00ed-b184-460a-d3a2-bc12a9781ae8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computer science\n",
            "['computer', 'science']\n",
            "[['doc1', 'doc2'], ['doc1', 'doc2']]\n",
            "{'doc2', 'doc1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  print(\"Enter quit to exit\")\n",
        "  rs = input(\"Enter the query: \")\n",
        "  if rs == \"quit\":\n",
        "    break\n",
        "  # print(rs)\n",
        "  r = search(rs)\n",
        "  print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmKMSigA4WsO",
        "outputId": "93bf49c9-63b9-49b5-ffff-18913142a63f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter quit to exit\n",
            "Enter the query: computer\n",
            "['computer']\n",
            "[['doc1', 'doc2']]\n",
            "{'doc2', 'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: computer science\n",
            "['computer', 'science']\n",
            "[['doc1', 'doc2'], ['doc1', 'doc2']]\n",
            "{'doc2', 'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: computer examinatio \n",
            "['computer', 'examinatio']\n",
            "not found\n",
            "Enter quit to exit\n",
            "Enter the query: practical examination\n",
            "['practical', 'examination']\n",
            "[['doc1', 'doc2'], ['doc1', 'doc2']]\n",
            "{'doc2', 'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: students examination'\n",
            "['students', 'examination']\n",
            "[['doc1'], ['doc1', 'doc2']]\n",
            "{'doc1'}\n",
            "Enter quit to exit\n",
            "Enter the query: \n",
            "[]\n",
            "[]\n",
            "no\n",
            "Enter quit to exit\n",
            "Enter the query: ok\n",
            "['ok']\n",
            "not found\n",
            "Enter quit to exit\n",
            "Enter the query: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "doc = {\n",
        "    \"doc1\": \"Ai is a ML?\",\n",
        "    \"doc2\": \"DS is maths!\"\n",
        "}\n",
        "\n",
        "i = {}\n",
        "sw = ['is', 'a']\n",
        "\n",
        "for k, v in doc.items():\n",
        "    v = v.lower()\n",
        "    v = v.strip(\".!?\")\n",
        "    words = v.split()\n",
        "\n",
        "    for w in words:\n",
        "        if w in sw:\n",
        "            continue\n",
        "        if w not in i:\n",
        "            i[w] = []\n",
        "        if k not in i[w]:\n",
        "            i[w].append(k)\n",
        "\n",
        "print(i)\n",
        "\n",
        "\n",
        "def search(q):\n",
        "    q = q.lower().strip(\"?.!\")\n",
        "    q = q.split()\n",
        "    l = []\n",
        "\n",
        "    for w in q:\n",
        "        if w in i:\n",
        "            l.append(i[w])\n",
        "\n",
        "    if len(l) == 0:\n",
        "        return \"not found\"\n",
        "\n",
        "    if len(l) == 1:\n",
        "        return l[0]\n",
        "\n",
        "    if len(l) > 1:\n",
        "        return list(set(l[0]).intersection(*l[1:]))\n",
        "\n",
        "print(search(\"computer\"))\n",
        "print(search(\"AI and ML\"))\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmfL0ZStOS2c",
        "outputId": "f097c7d1-366e-4fdf-899d-5680d57dd47b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ai': ['doc1'], 'ml': ['doc1'], 'ds': ['doc2'], 'maths': ['doc2']}\n",
            "not found\n",
            "['doc1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = [[1], [1, 2]]\n",
        "print(set(l[0]).intersection(*l[1:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGFHP1JGOd-L",
        "outputId": "a30a6a5e-9abd-44c1-808a-e065aa8fc343"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "6RfGNyxBO17_"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqhqod9iRCy3",
        "outputId": "f84dfa29-66b8-48da-f911-24a2e192b0af"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = \"\"\"\n",
        "Today is Information Retrieval Practical Exam.\n",
        "I an a computer sicence student.\n",
        "computer science students are appearing for IR exam today.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_qS094sPRrl8"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(q):\n",
        "  r = qa_pipeline(question=q, context=c)\n",
        "  print(r['score'])\n",
        "  if r['score'] < 0.2:\n",
        "      return \"I don't know\"\n",
        "  print(r['answer'])"
      ],
      "metadata": {
        "id": "N19o20elSCSD"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"Who am i?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38RSSqtUSJXf",
        "outputId": "abd18dfd-f662-400a-c620-6a4738d2a686"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.44715407490730286\n",
            "a computer sicence student\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"what is today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ-cbTrASR3c",
        "outputId": "50cbfe3f-18b3-469a-8baa-cd2bffe9b393"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9671644568443298\n",
            "Information Retrieval Practical Exam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"what i'm gonna do taoday?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "L9BfieLASUlQ",
        "outputId": "ba1c98a2-1f9a-4943-8a7a-a2492e5acf81"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.19836826622486115\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"what i'm gonna do today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWmpXOO2ScX7",
        "outputId": "4a4d3e15-5872-41f3-f8c0-ff70e6146e77"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.46084555983543396\n",
            "IR exam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"tell my name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "69VYQjo6SjqT",
        "outputId": "44b1a173-25b8-4dfd-fa58-39f6afa441f2"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15932273864746094\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"explain AI?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "0tXBat-9SoZk",
        "outputId": "495843d2-e4a1-491e-ed83-4b90d6d57f3d"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.04368548467755318\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c += \"\"\"\n",
        "  my name is art.\n",
        "  AI is a field that deals with making rational systems\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uMRWEpAbSr_x"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"what is my name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so9_QQ3jUJ1U",
        "outputId": "5e4e2f59-5491-45b1-83fc-88b23a6f5fec"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9700301289558411\n",
            "art\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"what is AI?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9w4bkm9ULfX",
        "outputId": "1964b432-a76d-4102-e0f8-b4906ff0659e"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8422307372093201\n",
            "a field that deals with making rational systems\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QoX4iJgxW0jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a program to calculate precision, recall and F-measure where true\n",
        "positive is 60, false positive is 30 and false negative is 20. [20]\n",
        "Recall= TP /TP+FN\n",
        "Precision = TP / TP+FP\n",
        "F-score = 2 * (Precision * Recall) / (Precision + Recall)"
      ],
      "metadata": {
        "id": "D5s2n6U1ZJWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate(tp, fp, fn, tn=0):\n",
        "    tn = 10\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    recall = tp / (tp + fn)\n",
        "    precision = tp / (tp + fp)\n",
        "    f_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return recall, precision, f_score, accuracy\n",
        "\n",
        "print(calculate(60, 30, 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYzzXcfkZJ2_",
        "outputId": "042f060e-36c9-40d5-bc60-1d7f378b5317"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.75, 0.6666666666666666, 0.7058823529411765, 0.5833333333333334)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CK6LjaB2ZTCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Develop a spelling correction module using edit distance algorithms and\n",
        "find the edit distance between strings “nature” and “creature”"
      ],
      "metadata": {
        "id": "o7AWlu--bf-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMu8Tkd8bgzh",
        "outputId": "75bbaa4b-e59d-4cf1-952d-473c97a8bc5e"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "# Edit distance\n",
        "print(Levenshtein.distance(\"kitten\", \"sitting\"))  # 3\n",
        "print(Levenshtein.distance(\"nature\", \"creature\"))  # 3\n",
        "\n",
        "\n",
        "# Similarity ratio\n",
        "print(Levenshtein.ratio(\"kitten\", \"sitting\"))  # 0.615..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYwxL3NkcZHD",
        "outputId": "9a865e0e-d927-4903-9fd6-273e25c66d30"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "3\n",
            "0.6153846153846154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-by-step transformations (3 operations):\n",
        "1. Insert 'c' at start: nature → cnature\n",
        "2. Substitute 'a' with 'r': cnature → crnature\n",
        "3. Substitute 'n' with 'e': crnature → creature"
      ],
      "metadata": {
        "id": "tUStfw3CeAfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein_distance(s1, s2):\n",
        "    m = len(s1)\n",
        "    n = len(s2)\n",
        "    dp = []\n",
        "    for _ in range(m + 1):\n",
        "      dp.append([0] * (n + 1))\n",
        "      print(dp)\n",
        "    print()\n",
        "\n",
        "\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "        print(dp)\n",
        "    print()\n",
        "\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "        print(dp)\n",
        "    print()\n",
        "\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if s1[i-1] == s2[j-1]:\n",
        "                dp[i][j] = dp[i-1][j-1]\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(\n",
        "                    dp[i-1][j],    # deletion\n",
        "                    dp[i][j-1],    # insertion\n",
        "                    dp[i-1][j-1]   # substitution\n",
        "                )\n",
        "    return dp[m][n]\n",
        "\n",
        "# Test with \"nature\" vs \"creature\"\n",
        "print(levenshtein_distance(\"nature\", \"creature\"))  # Output: 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTora7ZBc5kw",
        "outputId": "e7332d27-2e6c-45ef-ddb4-5ffe5a564a6e"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 1, 2, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 1, 2, 3, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 1, 2, 3, 4, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 1, 2, 3, 4, 5, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 1, 2, 3, 4, 5, 6, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 1, 2, 3, 4, 5, 6, 7, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 1, 2, 3, 4, 5, 6, 7, 8], [1, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 10):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4Q6g3theVec",
        "outputId": "b76e36d3-8a04-4c38-c633-49e1cb6895cf"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from pprint import pprint\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "\n",
        "dt = {\n",
        "   'doc1': 'Python is Awesome and great.',\n",
        "   'doc2': 'Java is great or cool.',\n",
        "   'doc3': 'Python is good.  '\n",
        "}\n",
        "\n",
        "\n",
        "inverted_index={}\n",
        "\n",
        "\n",
        "for k,v in dt.items():\n",
        " v = v.lower()\n",
        " for p in punctuation:\n",
        "   v = v.replace(p, '')\n",
        " for word in v.split():\n",
        "   if word in stop_words:\n",
        "     continue\n",
        "   if word not in inverted_index:\n",
        "     inverted_index[word] = []\n",
        "   if k not in inverted_index[word]:\n",
        "     inverted_index[word].append(k)\n",
        "\n",
        "\n",
        "pprint(inverted_index)\n",
        "\n",
        "\n",
        "# Boolean Retrieval Model\n",
        "def search_boolean(word1, word2, operator):\n",
        " try:\n",
        "   a = inverted_index[word1]\n",
        "   b = inverted_index[word2]\n",
        " except KeyError:\n",
        "   return 'not found'\n",
        " if operator == 'and':\n",
        "   if set(a) & set(b) == set():\n",
        "     return 'not found'\n",
        "   return set(a) & set(b)\n",
        " elif operator == 'or':\n",
        "   if set(a) | set(b) == set():\n",
        "     return 'not found'\n",
        "   return set(a) | set(b)\n",
        " elif operator == 'not':\n",
        "   if set(a) - set(b) == set():\n",
        "     return 'not found'\n",
        "   return set(a) - set(b)\n",
        "\n",
        "\n",
        "print(inverted_index['python'])\n",
        "print(inverted_index['cool'])\n",
        "print(inverted_index['good'])\n",
        "print('python', 'and', 'cool', search_boolean('python', 'cool', 'and'))\n",
        "print('python', 'or', 'cool', search_boolean('python', 'cool', 'or'))\n",
        "print('python' , 'not' 'good', search_boolean('python', 'good', 'not'))\n",
        "print('ypython', 'and', 'gooud',  search_boolean('ypython', 'gooud', 'and'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6zQtJGrebvq",
        "outputId": "e7a3d9d5-311a-435c-915e-7efb1529bd8f"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'awesome': ['doc1'],\n",
            " 'cool': ['doc2'],\n",
            " 'good': ['doc3'],\n",
            " 'great': ['doc1', 'doc2'],\n",
            " 'java': ['doc2'],\n",
            " 'python': ['doc1', 'doc3']}\n",
            "['doc1', 'doc3']\n",
            "['doc2']\n",
            "['doc3']\n",
            "python and cool not found\n",
            "python or cool {'doc2', 'doc3', 'doc1'}\n",
            "python notgood {'doc1'}\n",
            "ypython and gooud not found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = set([1,2,4])\n",
        "b = set([1,2,3])\n",
        "print(a & b)\n",
        "print(a | b)\n",
        "print(a - b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn8fqzDhka2Q",
        "outputId": "38d6b31a-e833-48fa-8eeb-d3bb0f4b57a4"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1, 2}\n",
            "{1, 2, 3, 4}\n",
            "{4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Given values\n",
        "TP = 60  # True Positives\n",
        "FP = 30  # False Positives\n",
        "FN = 20  # False Negatives\n",
        "\n",
        "# Manual calculations\n",
        "def calculate_metrics(tp, fp, fn):\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "precision, recall, f1_score = calculate_metrics(TP, FP, FN)\n",
        "\n",
        "print(\"Manual Calculations:\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1_score:.4f}\")\n",
        "\n",
        "# Using scikit-learn's evaluation toolkit\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, average_precision_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Create dummy arrays to represent predictions and ground truth\n",
        "# Let's assume we have 110 samples total (TP + FP + FN = 60 + 30 + 20 = 110)\n",
        "# We'll create arrays where 1 represents positive class and 0 represents negative\n",
        "\n",
        "# Ground truth: 80 positives (TP + FN) and 30 negatives (FP is all false positives)\n",
        "y_true = np.array([1]*80 + [0]*30)\n",
        "\n",
        "# Predictions: 90 predicted positives (TP + FP) and 20 predicted negatives (FN is false negatives)\n",
        "y_pred = np.array([1]*60 + [0]*20 + [1]*30)\n",
        "print(y_true)\n",
        "print(y_pred)\n",
        "print(\"\\nUsing scikit-learn:\")\n",
        "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_true, y_pred):.4f}\")\n",
        "\n",
        "# Average Precision (AP)\n",
        "print(f\"Average Precision: {average_precision_score(y_true, y_pred):.4f}\")\n",
        "\n",
        "# Classification report with additional metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVfs5xOIkonm",
        "outputId": "31cb40b7-113b-4033-f014-88593a40bcc4"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Calculations:\n",
            "Precision: 0.6667\n",
            "Recall: 0.7500\n",
            "F1-Score: 0.7059\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "\n",
            "Using scikit-learn:\n",
            "Precision: 0.6667\n",
            "Recall: 0.7500\n",
            "F1-Score: 0.7059\n",
            "Average Precision: 0.6818\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        30\n",
            "           1       0.67      0.75      0.71        80\n",
            "\n",
            "    accuracy                           0.55       110\n",
            "   macro avg       0.33      0.38      0.35       110\n",
            "weighted avg       0.48      0.55      0.51       110\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Load the 20 Newsgroups dataset\n",
        "categories = ['rec.sport.hockey', 'comp.graphics', 'sci.med', 'talk.politics.guns']\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Since the original dataset doesn't have sentiment labels, we'll create artificial ones\n",
        "# For demonstration, we'll consider some categories as \"positive\" and others as \"negative\"\n",
        "# Note: In a real project, you would use actual sentiment-labeled data\n",
        "\n",
        "# Create artificial sentiment labels (0=negative, 1=positive)\n",
        "category_to_sentiment = {\n",
        "    'rec.sport.hockey': 1,    # Positive (sports)\n",
        "    'comp.graphics': 0,       # Negative (technical)\n",
        "    'sci.med': 1,            # Positive (health)\n",
        "    'talk.politics.guns': 0   # Negative (controversial)\n",
        "}\n",
        "\n",
        "y = np.array([category_to_sentiment[newsgroups.target_names[cat]] for cat in newsgroups.target])\n",
        "\n",
        "# Build a Naïve Bayes pipeline with TF-IDF vectorization\n",
        "model = make_pipeline(\n",
        "    TfidfVectorizer(stop_words='english', max_features=10000),\n",
        "    MultinomialNB()\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(newsgroups.data, y)\n",
        "\n",
        "# Evaluate on test data\n",
        "test_data = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "y_test = np.array([category_to_sentiment[test_data.target_names[cat]] for cat in test_data.target])\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(test_data.data)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Example prediction\n",
        "sample_text = \"I love hockey and it's great for health\"\n",
        "print(f\"Prediction for '{sample_text}': {'Positive' if model.predict([sample_text])[0] else 'Negative'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYHzGLd4s3KH",
        "outputId": "6829a81d-ac94-446e-cf3b-b5ed628fb2a6"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.30      0.39       753\n",
            "           1       0.54      0.77      0.63       795\n",
            "\n",
            "    accuracy                           0.54      1548\n",
            "   macro avg       0.55      0.54      0.51      1548\n",
            "weighted avg       0.55      0.54      0.52      1548\n",
            "\n",
            "Prediction for 'I love hockey and it's great for health': Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset with text and sentiment labels (0=negative, 1=positive)\n",
        "data = {\n",
        "    'text': [\n",
        "        'I love this product',\n",
        "        'This is terrible',\n",
        "        'Great experience',\n",
        "        'Worst purchase ever',\n",
        "        'Highly recommended',\n",
        "        'I hate it',\n",
        "        'Awesome quality',\n",
        "        'Poor service',\n",
        "        'Very satisfied',\n",
        "        'Disappointing'\n",
        "    ],\n",
        "    'sentiment': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
        "}"
      ],
      "metadata": {
        "id": "lFHS2VoVu3Wf"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['sentiment'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create a pipeline:\n",
        "# 1. Convert text to word counts\n",
        "# 2. Apply Naïve Bayes classifier\n",
        "model = make_pipeline(\n",
        "    CountVectorizer(),\n",
        "    MultinomialNB()\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
        "\n",
        "# Make predictions\n",
        "test_phrases = [\"I'm happy with this\", \"It was bad\"]\n",
        "predictions = model.predict(test_phrases)\n",
        "\n",
        "for text, pred in zip(test_phrases, predictions):\n",
        "    print(f\"'{text}' -> {'Positive' if pred == 1 else 'Negative'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLVgzjDKvbx3",
        "outputId": "74271502-d3e9-45ea-ce5d-2c1e03ea7546"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  text  sentiment\n",
            "0  I love this product          1\n",
            "1     This is terrible          0\n",
            "2     Great experience          1\n",
            "3  Worst purchase ever          0\n",
            "4   Highly recommended          1\n",
            "5            I hate it          0\n",
            "6      Awesome quality          1\n",
            "7         Poor service          0\n",
            "8       Very satisfied          1\n",
            "9        Disappointing          0\n",
            "Test accuracy: 0.0\n",
            "'I'm happy with this' -> Positive\n",
            "'It was bad' -> Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Create dummy dataset\n",
        "documents = [\n",
        "    (\"God is love\", \"soc.religion.christian\"),\n",
        "    (\"OpenGL on the GPU is fast\", \"comp.graphics\"),\n",
        "    (\"There is no God\", \"alt.atheism\"),\n",
        "    (\"Medical breakthroughs in cancer\", \"sci.med\"),\n",
        "    (\"Jesus saves\", \"soc.religion.christian\"),\n",
        "    (\"3D rendering techniques\", \"comp.graphics\"),\n",
        "    (\"Atheism and secularism\", \"alt.atheism\"),\n",
        "    (\"New vaccine development\", \"sci.med\")\n",
        "]\n",
        "\n",
        "# Separate text and labels\n",
        "texts = [doc[0] for doc in documents]\n",
        "labels = [doc[1] for doc in documents]\n",
        "\n",
        "# 2. Convert text to numerical features\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# 3. Create and train SVM classifier\n",
        "clf = svm.SVC(kernel='linear')  # Linear kernel works well for text\n",
        "clf.fit(X, labels)\n",
        "\n",
        "# 4. Test the classifier\n",
        "test_docs = [\n",
        "    \"Prayer and faith\",\n",
        "    \"Computer graphics hardware\",\n",
        "    \"Why I don't believe\",\n",
        "    \"Clinical trials results\"\n",
        "]\n",
        "predicted = clf.predict(vectorizer.transform(test_docs))\n",
        "\n",
        "# 5. Show results\n",
        "for doc, category in zip(test_docs, predicted):\n",
        "    print(f\"Document: '{doc}'\")\n",
        "    print(f\"Predicted category: {category}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9Ul89Drvdcu",
        "outputId": "5bc4cee8-dbfe-4667-8e5a-4d406f5b5879"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document: 'Prayer and faith'\n",
            "Predicted category: alt.atheism\n",
            "\n",
            "Document: 'Computer graphics hardware'\n",
            "Predicted category: soc.religion.christian\n",
            "\n",
            "Document: 'Why I don't believe'\n",
            "Predicted category: soc.religion.christian\n",
            "\n",
            "Document: 'Clinical trials results'\n",
            "Predicted category: soc.religion.christian\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "\n",
        "docs = [\n",
        "   'cats are cute',\n",
        "   'cats are agile',\n",
        "   'cats are fast',\n",
        "   'sky is blue',\n",
        "   'sky is bright',\n",
        "   'sky is beautiful',\n",
        "   'sun is up',\n",
        "   'sun is yellow',\n",
        "   'sun is shiny',\n",
        "   'cat is quick'\n",
        "]\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(docs)\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(X)\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "\n",
        "for cluster_id in range(3):\n",
        "   print(f\"Cluster{cluster_id+1}:\")\n",
        "   for i, doc in enumerate(docs):\n",
        "       if cluster_labels[i] == cluster_id:\n",
        "           print(f\"    '{doc}'\")\n",
        "\n",
        "\n",
        "silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "print(f\"\\nSilhouette Score: {silhouette_avg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL40ekrNwkG3",
        "outputId": "2d60543d-05eb-4649-edb1-27f631294c79"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster1:\n",
            "    'sun is up'\n",
            "    'sun is yellow'\n",
            "    'sun is shiny'\n",
            "Cluster2:\n",
            "    'cats are cute'\n",
            "    'cats are agile'\n",
            "    'cats are fast'\n",
            "    'cat is quick'\n",
            "Cluster3:\n",
            "    'sky is blue'\n",
            "    'sky is bright'\n",
            "    'sky is beautiful'\n",
            "\n",
            "Silhouette Score: 0.19155480799479851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "import requests\n",
        "\n",
        "\n",
        "def crawl(url):\n",
        "   try:\n",
        "       response = requests.get(url)\n",
        "       response.raise_for_status()\n",
        "       soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "       print(f\"Title: {soup.title.string} url: {url}\")\n",
        "   except requests.exceptions.RequestException as e:\n",
        "       print(f\"Error: {e}\")\n",
        "\n",
        "\n",
        "crawl('https://google.com')\n",
        "crawl('https://en.wikipedia.org')\n",
        "crawl('https://codevit.vercel.app')\n",
        "crawl('https://imagen-xi.vercel.app')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TO4yzccwsGX",
        "outputId": "f64b1eae-7ef8-41c3-ee2a-9de38fb6324a"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Google url: https://google.com\n",
            "Title: Wikipedia, the free encyclopedia url: https://en.wikipedia.org\n",
            "Title: CodeVit url: https://codevit.vercel.app\n",
            "Title: Imagen url: https://imagen-xi.vercel.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "\n",
        "def pagerank_nx(graph):\n",
        "\n",
        "\n",
        " graph_nx = nx.DiGraph(graph)\n",
        " pageranks = nx.pagerank(graph_nx)\n",
        " return pageranks\n",
        "\n",
        "\n",
        "web_graph = {\n",
        "   'A': ['B', 'C'],\n",
        "   'B': ['A', 'C'],\n",
        "   'C': ['A', 'D'],\n",
        "   'D': ['A'],\n",
        "}\n",
        "\n",
        "\n",
        "pagerank_scores = pagerank_nx(web_graph)\n",
        "print(\"PageRank Scores:\")\n",
        "\n",
        "\n",
        "for page, score in pagerank_scores.items():\n",
        "   print(f\"{page}: {score:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sorted_ranks = sorted(pagerank_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "\n",
        "for i, (page, score) in enumerate(sorted_ranks):\n",
        "   print(f\"Rank {i+1}: {page} ({score:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HeiACfxww4e",
        "outputId": "24e9bc8a-7fa8-4002-8684-6b52eec96257"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PageRank Scores:\n",
            "A: 0.3710\n",
            "B: 0.1952\n",
            "C: 0.2781\n",
            "D: 0.1557\n",
            "Rank 1: A (0.3710)\n",
            "Rank 2: C (0.2781)\n",
            "Rank 3: B (0.1952)\n",
            "Rank 4: D (0.1557)\n"
          ]
        }
      ]
    }
  ]
}